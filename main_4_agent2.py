from typing import Optional, List
from dotenv import load_dotenv
from pydantic import BaseModel, Field, field_validator, PrivateAttr

from langchain.tools import BaseTool
from langchain.memory import ConversationBufferWindowMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.prompts import PromptTemplate
from langchain.agents import AgentExecutor, create_react_agent
from langchain.agents.openai_functions_agent.base import create_openai_functions_agent
from langchain import hub


GLOBAL_LLM = None


# --- 1. Agent 2 ç›¸å…³çš„ Pydantic æ¨¡å‹ ---

class FileAnalysisParams(BaseModel):
    """ç”¨äºä»ç”¨æˆ·è¯·æ±‚ä¸­ï¼Œä¸¥æ ¼æå–å‡ºåˆ†ææ–‡ä»¶æ‰€éœ€çš„å…·ä½“é—®é¢˜ã€‚"""
    user_query: str = Field(description="ç”¨æˆ·å¸Œæœ›å¯¹å›ºå®šæŠ¥å‘Šæå‡ºçš„å…·ä½“é—®é¢˜ï¼Œä¾‹å¦‚ '2023å¹´è¥æ”¶åŒæ¯”å¢é€Ÿæ˜¯å¤šå°‘?'ã€‚")

    @field_validator("user_query")
    def validate_user_query(cls, value):
        if not value:
            raise ValueError("åˆ†æé—®é¢˜ä¸èƒ½ä¸ºç©º")
        return value


# --- 2. Agent 2 æ ¸å¿ƒ Tool å®šä¹‰ ---
class FinancialReportAnalysisTool(BaseTool):
    """
    ç”¨äºåˆ†æä¸€ä¸ªå›ºå®šè·¯å¾„ä¸‹çš„æŠ¥å‘Šçš„å·¥å…·ã€‚Agent åªéœ€è¦æå–ç”¨æˆ·çš„å…·ä½“é—®é¢˜ã€‚
    """

    name: str = "report_analysis_tool"
    description: str = (
        "å½“ç”¨æˆ·è¦æ±‚åˆ†ææŠ¥å‘Šï¼ˆä¾‹å¦‚ï¼Œè¯¢é—®å…³äºå…¬å¸è´¢åŠ¡æ•°æ®çš„é—®é¢˜ï¼‰æ—¶ï¼Œ"
        "å¿…é¡»è°ƒç”¨æ­¤å·¥å…·ï¼Œå¹¶ä¸¥æ ¼å¡«å…… user_query å­—æ®µã€‚"
        "æ­¤å·¥å…·ä¼šè‡ªåŠ¨ä»ä¸€ä¸ª**å›ºå®šã€é¢„è®¾çš„è·¯å¾„**è¯»å–æŠ¥å‘Šå†…å®¹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·é—®é¢˜è¿›è¡Œåˆ†æã€‚"
    )
    args_schema: type[BaseModel] = FileAnalysisParams

    FIXED_REPORT_PATH: str = "./unified_outputs/002216/financial_statements.csv"


    def _read_file_content(self) -> str:
        """ä»å›ºå®šçš„ã€ç¡®å®šçš„è·¯å¾„è¯»å–æ–‡ä»¶å†…å®¹ã€‚"""
        actual_path = self.FIXED_REPORT_PATH
        try:
            with open(actual_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            # å¦‚æœæ˜¯å›ºå®šçš„æ–‡ä»¶ï¼Œå¦‚æœæ‰¾ä¸åˆ°ï¼Œè¯´æ˜æ˜¯ç³»ç»Ÿé…ç½®é—®é¢˜ï¼Œè¿”å›é”™è¯¯
            return f"ç³»ç»Ÿé…ç½®é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›ºå®šæŠ¥å‘Šæ–‡ä»¶: {actual_path}"
        except Exception as e:
            return f"è¯»å–å›ºå®šæŠ¥å‘Šæ–‡ä»¶æ—¶å‡ºé”™: {e}"

    def _run(self, user_query: str):
        """Tool çš„å®é™…æ‰§è¡Œé€»è¾‘ï¼šè¯»å–å›ºå®šæ–‡ä»¶ï¼Œç„¶åé€ç»™ LLM åˆ†æã€‚"""

        llm = globals().get("GLOBAL_LLM")
        # 1. Tool å†…éƒ¨è¯»å–å›ºå®šæ–‡ä»¶å†…å®¹
        report_content = self._read_file_content()

        if report_content.startswith("ç³»ç»Ÿé…ç½®é”™è¯¯"):
            return report_content

        # 2. æ„å»ºæœ€ç»ˆåˆ†æ Prompt
        # ğŸŒŸ å‡è®¾ llm å®ä¾‹åœ¨ Tool å¤–éƒ¨å·²åˆå§‹åŒ–å¹¶ä¼ å…¥ï¼ˆæˆ–è€…åƒåŸä»£ç ä¸€æ ·å…¨å±€å¯ç”¨ï¼‰
        # è¿™é‡Œéœ€è¦ç¡®ä¿ llm å®ä¾‹æ˜¯å¯ç”¨çš„
        # ä¸ºäº†ç®€æ´ï¼Œæˆ‘ä»¬å‡è®¾llmæ˜¯å¯ç”¨çš„

        analysis_prompt = (
            f"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢åŠ¡åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å›ºå®šæŠ¥å‘Šå†…å®¹ï¼Œ"
            f"**ç®€æ´ã€å‡†ç¡®åœ°**å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜ã€‚\n\n"
            f"--- æŠ¥å‘Šå†…å®¹ ---\n"
            f"{report_content}\n"
            f"-----------------\n\n"
            f"ç”¨æˆ·é—®é¢˜: {user_query}"
        )

        # 3. è°ƒç”¨ LLM è¿›è¡Œåˆ†æ
        try:
            # å‡è®¾ llm å®ä¾‹å·²åˆå§‹åŒ–å¹¶å¯ç”¨
            analysis_result = llm.invoke(analysis_prompt).content
            return f"å¯¹å›ºå®šæŠ¥å‘Šçš„åˆ†æç»“æœï¼š\n{analysis_result}"
        except Exception as e:
            return f"æŠ¥å‘Šåˆ†æå¤±è´¥ï¼ŒLLMè°ƒç”¨é”™è¯¯: {e}"

    def _arun(self, *args, **kwargs):
        raise NotImplementedError("Async run not implemented")


class TerminateTool(BaseTool):
    """ç”¨äºç»ˆæ­¢Agentæµç¨‹å¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆçš„å·¥å…·"""
    name: str = "ç»ˆæ­¢"
    description: str = (
        "å½“å·¥å…·è¿”å›ç»“æœå·²è¶³å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜ã€æˆ–æ•°æ®ç¼ºå¤±æ— æ³•ç»§ç»­åˆ†æã€æˆ–ç”¨æˆ·è¯·æ±‚æ˜¯é—²èŠæ—¶ï¼Œ"
        "å¿…é¡»è°ƒç”¨æ­¤å·¥å…·ç»ˆæ­¢æµç¨‹ï¼Œå¹¶å°†æœ€ç»ˆå›å¤å¡«å……åˆ°Action Inputä¸­ã€‚"
    )
    # ç»ˆæ­¢å·¥å…·æ— éœ€å‚æ•°ï¼Œæ‰€ä»¥args_schemaç”¨ç©ºçš„BaseModel
    args_schema: type[BaseModel] = BaseModel

    def _run(self):
        """è°ƒç”¨æ­¤å·¥å…·æ—¶ç›´æ¥è¿”å›ç©ºï¼ˆæ ¸å¿ƒæ˜¯è§¦å‘ç»ˆæ­¢é€»è¾‘ï¼Œæ— éœ€å®é™…æ‰§è¡Œï¼‰"""
        return "æµç¨‹ç»ˆæ­¢"

    def _arun(self, *args, **kwargs):
        raise NotImplementedError("Async run not implemented")


# --- 3. Agent 2 æ ¸å¿ƒç»„ä»¶å®šä¹‰ ---

# æˆ‘ä»¬å°†å¤ç”¨ Agent 1 çš„ LLM é…ç½®å’Œå†…å­˜ï¼Œä½†å®šä¹‰ä¸€ä¸ªæ–°çš„ Agent/Executor

def create_analysis_agent(llm: ChatOpenAI, memory: ConversationBufferWindowMemory):
    """åˆ›å»ºå¹¶è¿”å›æ–‡ä»¶åˆ†æ Agent Executor"""

    # 1. å®šä¹‰å·¥å…·åˆ—è¡¨ (Agent 2 åªéœ€è¦åˆ†æå·¥å…·)
    analysis_tools: List[BaseTool] = [FinancialReportAnalysisTool(), TerminateTool()]

    # 2. å®šä¹‰ Agent çš„ Prompt
    # analysis_system_prompt = (
    #     "ä½ æ˜¯ä¸€ä½èµ„æ·±æ•°æ®åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®çˆ¬å–åˆ°çš„å…¬å¸è´¢æŠ¥ã€æ–°é—»ä¸ç›¸å…³è‚¡ç¥¨ä¿¡æ¯åˆ†æè¯·æ±‚é—®é¢˜ï¼Œå¹¶è¿›è¡Œä»¥ä¸‹åˆ¤æ–­ï¼š"
    #     # "1. **å¦‚æœ**ç”¨æˆ·å¹¶æ²¡æœ‰æ‰§è¡Œå®Œæ•°æ®çˆ¬å–agentï¼Œåˆ™ä¸è°ƒç”¨æ­¤agentã€‚åªæœ‰åœ¨æ•°æ®çˆ¬å–agentæ‰§è¡Œå®Œåï¼Œç›¸åº”çš„æ–‡ä»¶æ•°æ®å·²ç»ä¸‹è½½ä¸‹æ¥ï¼Œæ‰è°ƒç”¨æ­¤agentåˆ†æ"
    #     # "2. **å¦‚æœ**ç›¸å…³æ•°æ®å·²ç»è¿‡æ•°æ®çˆ¬å–agentä¸‹è½½å¥½ï¼Œå¹¶ä¸”ç”¨æˆ·çš„è¯·æ±‚æ˜¯åˆ†æä¸€ä¸ªå…·ä½“æ–‡ä»¶å¹¶æå‡ºé—®é¢˜ï¼Œ"
    #     # "ä½ **å¿…é¡»**è°ƒç”¨ `financial_report_analysis_tool` å·¥å…·ï¼Œ"
    #     "3. å¦‚æœç”¨æˆ·æå‡ºäº†ä¸€ä¸ªå…³äºæŠ¥å‘Šçš„é—®é¢˜ï¼Œä½ **å¿…é¡»**è°ƒç”¨ `report_analysis_tool` å·¥å…·ï¼Œ"
    #     "   å¹¶ä¸¥æ ¼åªå°†ç”¨æˆ·æå‡ºçš„**å…·ä½“é—®é¢˜**å¡«å……åˆ° `user_query` å­—æ®µä¸­ã€‚"
    #     "4. ç»å¯¹ä¸è¦å°è¯•æå–æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶åï¼Œå› ä¸ºæ–‡ä»¶è·¯å¾„æ˜¯å›ºå®šçš„ï¼Œå·²ç»åœ¨å·¥å…·å†…éƒ¨è®¾ç½®ã€‚"
    #     "5. åœ¨è°ƒç”¨å·¥å…·ä¹‹å‰ï¼Œè¯·å‹¿ä»¥è‡ªç„¶è¯­è¨€å½¢å¼å›ç­”å…³äºæ–‡ä»¶å†…å®¹çš„é—®é¢˜ã€‚"
    # )

    react_system_prompt = """
    ä½ æ˜¯ä¸€ä½èµ„æ·±é‡‘èç ”ç©¶å‘˜ï¼Œè´Ÿè´£å‡†ç¡®å›ç­”ç”¨æˆ·çš„é‡‘èåˆ†ææé—®ã€‚

    ### æ ¸å¿ƒè§„åˆ™
    1. åªæœ‰å½“ç”¨æˆ·çš„é—®é¢˜éœ€è¦åˆ†æå›ºå®šæŠ¥å‘Šæ•°æ®æ—¶ï¼Œæ‰è°ƒç”¨å·¥å…·ï¼›
    2. å·¥å…·è°ƒç”¨åï¼Œè‹¥å¾—åˆ°æ˜ç¡®ç»“æœï¼ˆæˆ–æ˜ç¡®æ•°æ®ç¼ºå¤±ï¼‰ï¼Œç›´æ¥æ•´ç†æˆæœ€ç»ˆç­”æ¡ˆï¼Œæ— éœ€é‡å¤è°ƒç”¨å·¥å…·ï¼›
    3. é—²èŠã€æ— éœ€åˆ†ææ•°æ®çš„é—®é¢˜ï¼Œç›´æ¥å›å¤ï¼Œä¸è°ƒç”¨å·¥å…·ã€‚

    ### å¯ç”¨å·¥å…·
    ä½ ä»…èƒ½ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
    {tools}
    å·¥å…·åç§°åˆ—è¡¨ï¼š{tool_names}

    ### æ ¼å¼è¦æ±‚ï¼ˆäºŒé€‰ä¸€ï¼‰
    #### æƒ…å†µ1ï¼šéœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼ˆå¿…é¡»æŒ‰æ­¤æ ¼å¼ï¼‰
    Thought: [åˆ†æç”¨æˆ·é—®é¢˜ï¼Œè¯´æ˜ä¸ºä½•éœ€è¦è°ƒç”¨å·¥å…·ï¼Œå¦‚ä½•æ„é€ è¾“å…¥]
    Action: [å·¥å…·åç§°ï¼Œå¿…é¡»æ˜¯ {tool_names} ä¸­çš„ä¸€ä¸ª]
    Action Input: [å·¥å…·æ‰€éœ€å‚æ•°ï¼Œä»…å¡«å†™ç”¨æˆ·çš„å…·ä½“é—®é¢˜ï¼ˆçº¯æ–‡æœ¬ï¼‰]

    #### æƒ…å†µ2ï¼šæ— éœ€è°ƒç”¨å·¥å…·/å·²å¾—åˆ°ç»“æœæ—¶ï¼ˆå¿…é¡»æŒ‰æ­¤æ ¼å¼ç»ˆæ­¢ï¼‰
    Thought: [è¯´æ˜æ— éœ€è°ƒç”¨å·¥å…·çš„åŸå› ï¼ˆå¦‚ï¼šå·¥å…·å·²è¿”å›è¶³å¤Ÿæ•°æ®/ç”¨æˆ·é—®é¢˜æ˜¯é—²èŠï¼‰]
    Final Answer: [ç»™ç”¨æˆ·çš„æœ€ç»ˆå›å¤ï¼ˆçº¯æ–‡æœ¬ï¼‰]

    ### å¯¹è¯ä¸Šä¸‹æ–‡
    --- å¯¹è¯å†å² ---
    {chat_history}
    --- å†å²æ€è€ƒè¿‡ç¨‹ ---
    {agent_scratchpad}
    --- æœ€æ–°ç”¨æˆ·è¾“å…¥ ---
    {input}
    """

    analysis_prompt = ChatPromptTemplate.from_messages([
        ("system", react_system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # ä¿®æ­£3ï¼šæ­£ç¡®åˆ›å»ºPromptTemplateå¹¶å¡«å……{tools}/{tool_names}å ä½ç¬¦
    # æå–å·¥å…·æè¿°å’Œåç§°ï¼Œç”¨äºå¡«å……prompt
    tools_description = "\n".join([f"- {tool.name}ï¼š{tool.description}" for tool in analysis_tools])
    tool_names = ", ".join([tool.name for tool in analysis_tools])  # ç»“æœï¼šreport_analysis_tool, ç»ˆæ­¢

    react_prompt = PromptTemplate(
        template=react_system_prompt,
        input_variables=["input", "chat_history", "agent_scratchpad"],
        partial_variables={  # æå‰å¡«å……å›ºå®šçš„å·¥å…·ä¿¡æ¯
            "tools": tools_description,
            "tool_names": tool_names
        }
    )

    # 3. åˆ›å»º Agent
    analysis_agent = create_react_agent(
        llm=llm,
        tools=analysis_tools,
        prompt=react_prompt,
    )

    # 4. åˆ›å»º Agent Executor
    analysis_agent_executor = AgentExecutor(
        agent=analysis_agent,
        tools=analysis_tools,
        verbose=True,
        memory=memory,
        handle_parsing_errors="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†ä½ çš„è¯·æ±‚ï¼Œè¯·é‡æ–°æè¿°é—®é¢˜ã€‚",
        max_iterations=3,  # æœ€å¤š3æ¬¡å¾ªç¯ï¼ˆ1æ¬¡è°ƒç”¨å·¥å…·+1æ¬¡è¿”å›ç»“æœï¼Œè¶³å¤Ÿç”¨ï¼‰
        early_stopping_method="generate"  # è¾¾åˆ°æœ€å¤§è¿­ä»£æ—¶ç”Ÿæˆæœ€ç»ˆå›å¤
    )

    return analysis_agent_executor


# --- 4. è¿è¡Œå’Œæµ‹è¯•å‡½æ•° (å°† Agent 2 é›†æˆåˆ°è¿è¡Œæµç¨‹) ---

def run_analysis_agent_test():
    """æ¨¡æ‹Ÿæ–‡ä»¶åˆ†æ Agent çš„è¿è¡Œã€‚"""

    # ğŸŒŸ é‡æ–°ä½¿ç”¨ Agent 1 ä¸­å·²åˆå§‹åŒ–çš„ LLM å’Œ Memory
    load_dotenv()
    global GLOBAL_LLM
    llm = ChatOpenAI(
        model='deepseek-r1-250528',
        base_url='https://ark.cn-beijing.volces.com/api/v3',
        temperature=0.1,
    )
    GLOBAL_LLM = llm
    memory = ConversationBufferWindowMemory(
        memory_key="chat_history",
        k=5,
        return_messages=True
    )

    analysis_agent_executor = create_analysis_agent(llm, memory)

    print("--- ğŸ“„ æ–‡ä»¶åˆ†æ Agent æ¨¡æ‹Ÿå¯åŠ¨ ---")
    print("è¾“å…¥ 'é€€å‡º' æˆ– 'exit' ç»“æŸå¯¹è¯ã€‚")
    print("-" * 60)


    # ğŸŒŸ äº¤äº’å¼å¾ªç¯
    while True:
        user_input = input("ç”¨æˆ·: ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            print("å¯¹è¯ç»“æŸã€‚")
            break

        try:
            result = analysis_agent_executor.invoke({"input": user_input})
            ai_response = result["output"]
        except Exception as e:
            ai_response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {e}"
            print(f"Agent é”™è¯¯: {e}")

        print(f"AI: {ai_response}")
        print("-" * 60)


if __name__ == "__main__":
    # è¿è¡Œ Agent 2 çš„æµ‹è¯•
    run_analysis_agent_test()